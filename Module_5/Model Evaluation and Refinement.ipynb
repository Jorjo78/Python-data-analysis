{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (1.26.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/giorgiocavallo/Library/Python/3.11/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Current working directory: /Users/giorgiocavallo/Desktop/Python/coursera/IBM_data_analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install seaborn   ## install seaborn package \n",
    "import seaborn as sns  ## import seaborn package\n",
    "import matplotlib.pyplot as plt ## import matplotlib package\n",
    "# Set the working directory\n",
    "os.chdir('/Users/giorgiocavallo/Desktop/Python/coursera/IBM_data_analysis')\n",
    "\n",
    "# Get and print the new current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Current working directory: {current_directory}\")  ## f is used to format the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symboling  normalized-losses         make fuel-type aspiration  \\\n",
      "0          3                NaN  alfa-romero       gas        std   \n",
      "1          3                NaN  alfa-romero       gas        std   \n",
      "2          1                NaN  alfa-romero       gas        std   \n",
      "3          2              164.0         audi       gas        std   \n",
      "4          2              164.0         audi       gas        std   \n",
      "\n",
      "  num-of-doors   body-style drive-wheels engine-location  wheel-base  ...  \\\n",
      "0          two  convertible          rwd           front        88.6  ...   \n",
      "1          two  convertible          rwd           front        88.6  ...   \n",
      "2          two    hatchback          rwd           front        94.5  ...   \n",
      "3         four        sedan          fwd           front        99.8  ...   \n",
      "4         four        sedan          4wd           front        99.4  ...   \n",
      "\n",
      "   engine-size  fuel-system  bore  stroke compression-ratio horsepower  \\\n",
      "0          130         mpfi  3.47    2.68               9.0      111.0   \n",
      "1          130         mpfi  3.47    2.68               9.0      111.0   \n",
      "2          152         mpfi  2.68    3.47               9.0      154.0   \n",
      "3          109         mpfi  3.19    3.40              10.0      102.0   \n",
      "4          136         mpfi  3.19    3.40               8.0      115.0   \n",
      "\n",
      "   peak-rpm city-mpg  highway-mpg    price  \n",
      "0    5000.0       21           27  13495.0  \n",
      "1    5000.0       21           27  16500.0  \n",
      "2    5000.0       19           26  16500.0  \n",
      "3    5500.0       24           30  13950.0  \n",
      "4    5500.0       18           22  17450.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "## read the csv data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('automobile.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In sample evaluation: In-sample evaluation is the process of evaluating the model using the same data that was used to train the model.\n",
    "# Out of sample evaluation: Out-of-sample evaluation is the process of evaluating the model using a different data set than the data set used to train the model.\n",
    "from sklearn.model_selection import train_test_split ## import train_test_split function from sklearn.model_selection\n",
    "# Split the data into training and testing sets\n",
    "# The test_size parameter sets the proportion of data that is split into the testing set. In this example, 0.3 indicates that 30% of the data is used for testing.\n",
    "# The random_state parameter sets a seed for the random number generator, which allows for reproducibility.\n",
    "# what should I assign to x an y here? to x all variables except price and to y price\n",
    "x_data = df.drop('price', axis=1) ## assign all the variables except price to X, 1 means column and 0 means row. \n",
    "y_data = df['price'] ## assign the price column to y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=0) ## split the data into training and testing sets\n",
    "\n",
    "## x_data: features or independent variables\n",
    "## y_data: dataset target or dependent variable df['price']\n",
    "## X_train: training set features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generalization performance: Generalization performance is the ability of a model to perform well on new, unseen data.\n",
    "## Overfitting: Overfitting occurs when a model learns the detail and noise in the training data to the extent that it \n",
    "## negatively impacts the performance of the model on new data.\n",
    "## Generalization error:Generalization error refers to the difference in performance between a machine learning model on the training data and \n",
    "## its performance on unseen data (test/validation data). It measures how well the model can generalize its learned patterns to new, unseen examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation: Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "## The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into.\n",
    "## As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it is used to split the data into k groups.\n",
    "## Each group is called a fold. The model is trained on k-1 of the folds and evaluated on the kth fold.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data before cleaning: (205, 26)\n",
      "Shape of data after cleaning: (159, 26)\n",
      "Number of rows removed: 46\n",
      "\n",
      "Cross-validation scores: [ 0.7992442  -0.12911674 -0.69016955]\n",
      "Average CV score: -0.006680699095501767\n",
      "Number of features: 54\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 1: Remove all rows with missing values from the original dataframe\n",
    "df_clean = df.dropna()  # This removes any row that has at least one missing value\n",
    "\n",
    "# Step 2: Create new x_data and y_data from cleaned dataset\n",
    "x_data = df_clean.drop('price', axis=1)   ## 1 is column and 0 is row\n",
    "y_data = df_clean['price']\n",
    "\n",
    "# Step 3: Separate numeric and categorical columns\n",
    "# select_dtypes helps us filter columns by their data type\n",
    "numeric_features = x_data.select_dtypes(include=['int64', 'float64'])    # Get all numeric columns\n",
    "categorical_features = x_data.select_dtypes(include=['object'])          # Get all string/object columns\n",
    "\n",
    "# Step 4: Create dummy variables using pandas get_dummies\n",
    "# drop_first=True removes one category to avoid perfect multicollinearity\n",
    "# This transforms categorical variables into binary (0/1) columns\n",
    "dummy_variables = pd.get_dummies(categorical_features, drop_first=True)\n",
    "\n",
    "# Step 5: Combine numeric features with dummy variables\n",
    "# axis=1 means we're concatenating horizontally (adding columns)\n",
    "x_data_encoded = pd.concat([numeric_features, dummy_variables], axis=1) ## is like cbind in R  \n",
    "\n",
    "\n",
    "# Step 6: Perform cross-validation with the encoded features\n",
    "# LinearRegression(): Creates a new linear regression model\n",
    "# x_data_encoded: Our features including both numeric and encoded categorical variables\n",
    "# y_data: Our target variable (price)\n",
    "# cv=3: Splits the data into 3 folds for cross-validation\n",
    "scores = cross_val_score(LinearRegression(), x_data_encoded, y_data, cv=3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Shape of data before cleaning:\", df.shape)\n",
    "print(\"Shape of data after cleaning:\", df_clean.shape)\n",
    "print(\"Number of rows removed:\", df.shape[0] - df_clean.shape[0])\n",
    "print(\"\\nCross-validation scores:\", scores)           # Shows score for each fold\n",
    "print(\"Average CV score:\", scores.mean())           # Shows average performance\n",
    "print(\"Number of features:\", x_data_encoded.shape[1])  # Shows total number of features after encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10977.47449519 14792.70805292 17190.59779579 19763.86876839\n",
      " 11532.73702454 12163.46063011 13933.56402982 14753.51473473\n",
      "  3729.32269908  7559.81751971  8087.43955752  8088.1833249\n",
      "  8904.79706316 13165.84393595 10123.21329967 10479.58143707\n",
      " 10479.58143707 10728.41091986 15928.3686113   7595.31947877\n",
      "  9621.34692832  8944.98562839 10293.6158748  10359.59457109\n",
      "  9815.15834779  9629.24637504 10506.34541796 10724.89984939\n",
      " 10200.47586722  8556.57349846 10198.74985578 11166.03766625\n",
      " 25064.74021176  7424.05169538  7910.26697121  7930.8853138\n",
      "  7978.07011892  7897.58856767 10412.58002724 10731.33607458\n",
      " 10412.58002724 10731.33607458 10527.54367234 15171.77555123\n",
      " 21359.37382182 22041.29151217 20517.18216041 23310.1193315\n",
      " 27558.02534887  5828.89521227  6747.05954629  6994.47965735\n",
      "  8787.17473353  9250.94585218  8725.01840436  8743.45718323\n",
      "  8947.06872021  9249.02347736  6332.1084937  10054.92859534\n",
      "  7323.62228815 10202.54695965 11142.33538028 11894.87617943\n",
      " 10370.52647766 11131.43348114 11310.31489829 11961.04992895\n",
      " 11863.5353445  11904.03208204 11763.20006196 19551.44361065\n",
      " 20409.12200861 19125.03923812 19673.80068984 22341.39783116\n",
      " 22470.4171109   8214.95628174  8715.7231004   4378.67890115\n",
      "  8995.68896374  8494.92214508  8995.68896374 10611.332987\n",
      "  9798.89502051 11821.96787693 11872.05186413 11255.42490899\n",
      " 10861.3148349  13577.64995894 16810.67460043 14209.85852415\n",
      " 14756.6589172  -1905.54955877 15077.34708795 16989.78342768\n",
      " 17546.08254569  6427.1690725   6134.03635747  5703.66995213\n",
      "  7353.23246543  7789.24893084  9231.59382469  7163.598479\n",
      " 11860.74451957  8098.00258217 10624.42177537  8744.82279721\n",
      " 12163.41382807  8258.44463514  8951.1819856   8883.20220801\n",
      " 10103.82923034  9656.78381567 19701.16091662  8985.32430593\n",
      "  9204.14320897  9670.62871136 10967.64279283 10262.80519311\n",
      "  9012.53097951  9384.15312968 13014.56996932 13294.31968251\n",
      " 17255.30295087 17535.05266406 18842.90304739 18793.74290676\n",
      " 17962.55239479 20551.21793431 19965.8281255  29616.44513156\n",
      " 11408.9313055  13478.14118218 12258.0775333  12282.98187083\n",
      " 12798.83908024 26246.11574754 26777.89104753 27253.20398777\n",
      " 11857.51266553 10708.27663465 12183.83146492 11034.59543404\n",
      " 11808.86764897 14064.89997657 13693.73917002 10307.39076915\n",
      " 20842.7179046  21984.9991955  21085.21481954 22043.14558308\n",
      " 23888.59762865 24907.97856798 22173.11279374 25564.60310733\n",
      " 15874.84381442 27635.51779763 24234.61160665]\n"
     ]
    }
   ],
   "source": [
    "## Function cross_val_predict() returns the predicted values for each data point when it's in the testing set.\n",
    "## The function takes the following parameters:\n",
    "## model: The machine learning model\n",
    "## x_data: The features\n",
    "## y_data: The target variable\n",
    "## cv: The number of folds\n",
    "## The function returns an array of predicted values for each data point when it's in the testing set.\n",
    "## Import the required libraries\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict  ## from sklearn.model_selection import cross_val_predict\n",
    "yhat = cross_val_predict(LinearRegression(), x_data_encoded, y_data, cv=3) ## cross_val_predict() function returns the predicted values for each data\n",
    "## point when it's in the testing set.\n",
    "\n",
    "print(yhat) ## print the predicted values for each data point when it's in the testing set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting, underfitting and model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial degree 1: R-squared = 0.9162\n",
      "Polynomial degree 2: R-squared = -8.6131\n",
      "Polynomial degree 3: R-squared = -22.7896\n",
      "Polynomial degree 4: R-squared = -17.8442\n",
      "\n",
      "R-squared values for each polynomial degree:\n",
      "Degree 1: 0.9162\n",
      "Degree 2: -8.6131\n",
      "Degree 3: -22.7896\n",
      "Degree 4: -17.8442\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for polynomial regression and data splitting\n",
    "from sklearn.preprocessing import PolynomialFeatures  # For creating polynomial features\n",
    "from sklearn.linear_model import LinearRegression    # For linear regression model\n",
    "from sklearn.model_selection import train_test_split # For splitting data into train/test sets\n",
    "\n",
    "# Clean data by removing rows with missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "## Separate features (X) and target variable (y)\n",
    "## Extract numeric features excluding the price column\n",
    "numeric_features = df_clean.select_dtypes(include=['int64', 'float64']).drop('price', axis=1)\n",
    "# Extract categorical features\n",
    "categorical_features = df_clean.select_dtypes(include=['object'])\n",
    "\n",
    "# Convert categorical variables into binary (dummy) variables\n",
    "# drop_first=True removes one category to avoid multicollinearity\n",
    "dummy_variables = pd.get_dummies(categorical_features, drop_first=True)\n",
    "\n",
    "# Combine numeric and dummy variables into final feature matrix\n",
    "X = pd.concat([numeric_features, dummy_variables], axis=1)\n",
    "y = df_clean['price']  # Target variable (car price)\n",
    "\n",
    "# Split data into training (70%) and testing (30%) sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Initialize empty list to store R-squared values for each polynomial degree\n",
    "Rsqu_test = []\n",
    "\n",
    "# Test different polynomial degrees (1 through 4)\n",
    "order = [1, 2, 3, 4]\n",
    "for n in order:\n",
    "    # Create polynomial features of degree n\n",
    "    pr = PolynomialFeatures(degree=n)\n",
    "    # Transform training data into polynomial features\n",
    "    x_train_pr = pr.fit_transform(x_train)\n",
    "    # Transform test data using the same polynomial features\n",
    "    x_test_pr = pr.transform(x_test)\n",
    "    \n",
    "    # Create and train linear regression model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train_pr, y_train)\n",
    "    \n",
    "    # Calculate and store R-squared score on test set\n",
    "    r2_score = lr.score(x_test_pr, y_test)\n",
    "    Rsqu_test.append(r2_score)\n",
    "    \n",
    "    # Print R-squared score for current polynomial degree\n",
    "    print(f\"Polynomial degree {n}: R-squared = {r2_score:.4f}\")\n",
    "\n",
    "# Print final summary of R-squared values for all polynomial degrees\n",
    "print(\"\\nR-squared values for each polynomial degree:\")\n",
    "for degree, r2 in zip(order, Rsqu_test):\n",
    "    print(f\"Degree {degree}: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
